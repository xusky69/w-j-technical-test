{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba técnica W & J parte 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm8rrWj0yP1F"
      },
      "source": [
        "# Prueba técnica W & J parte 1\n",
        "- por David Ricardo Vivas Ordóñez\n",
        "\n",
        "For this first challenge we will build a news category classifier using Tensorflow and the [Transformers library](https://github.com/huggingface/transformers) by the [Huggingface team](https://github.com/huggingface). This library provides a relatively unified API for the use and training of a vast amount of Transformer models such as BERT and GPT-2. \n",
        "\n",
        "We will support ourselves on the [library documentation](https://huggingface.co/transformers/) and a [working example](https://www.kaggle.com/foolofatook/news-classification-using-bert). We will run this example on a google colab TPU environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjPxfFkk0Z8r"
      },
      "source": [
        "## Dependency loading, environment preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch-9o_aWSCPV"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7hICgP310gB",
        "outputId": "c368aa34-9333-4607-cbb7-909a812e943e"
      },
      "source": [
        "### descarga del dataset\n",
        "!gdown --id 18g0n5IrhTc_7uJlUTYjnavgnjkPrPVJp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18g0n5IrhTc_7uJlUTYjnavgnjkPrPVJp\n",
            "To: /content/News_Category_Dataset_v2.json\n",
            "83.9MB [00:00, 149MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYUDkU9DxIjv"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, TFAutoModel"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19BViv6X7AF2",
        "outputId": "6b17739f-3542-4bf9-bb25-cfb61f1a342a"
      },
      "source": [
        "# Taken from https://www.kaggle.com/philculliton/a-simple-tf-2-1-notebook\n",
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  grpc://10.81.140.218:8470\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.81.140.218:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.81.140.218:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-95w9Jdm1y00"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "aOVcv_DN1ArO",
        "outputId": "2036b884-dfb3-42df-d2f7-c7146489caf2"
      },
      "source": [
        "df = pd.read_json('/content/News_Category_Dataset_v2.json', lines=True)                                            # load dataset from drive\n",
        "\n",
        "# merge duplicate and similar categories, uncomment for raw dataset\n",
        "df['category'] = df['category'].map(lambda z :'ARTS & CULTURE' if z == 'ARTS' else z)\n",
        "df['category'] = df['category'].map(lambda z :'ARTS & CULTURE' if z == 'CULTURE & ARTS' else z)\n",
        "df['category'] = df['category'].map(lambda z :'THE WORLDPOST' if z == 'WORLDPOST' else z)\n",
        "df['category'] = df['category'].map(lambda z :'PARENTING' if z == 'PARENTS' else z)\n",
        "df['category'] = df['category'].map(lambda z :'ENVIRONMENT' if z == 'GREEN' else z)\n",
        "df['category'] = df['category'].map(lambda z :'FOOD & DRINK' if z == 'TASTE' else z)\n",
        "df['category'] = df['category'].map(lambda z :'STYLE & BEAUTY' if z == 'STYLE' else z)\n",
        "df['category'] = df['category'].map(lambda z :'EDUCATION' if z == 'COLLEGE' else z)\n",
        "\n",
        "df = df.sample(frac=1)                                                                                             # shuffling\n",
        "n_classes = df.category.nunique()                                                                                  # count number of unique categories\n",
        "df['category'] = pd.Categorical(df['category'])                                                                    \n",
        "df['category_label'] = df['category'].cat.codes\n",
        "categories = df['category'].cat.categories\n",
        "one_hot_labels = tf.keras.utils.to_categorical(df['category_label'], num_classes=n_classes, dtype = 'int32')       # create one_hot representation of each category\n",
        "dataset_size = len(one_hot_labels)\n",
        "df['category_label_one_hot'] = one_hot_labels.tolist()\n",
        "df['string_inputs'] = df['headline'] + df['short_description']\n",
        "df = df.sort_index(axis=1)                                                                                         # sort dataset\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>category</th>\n",
              "      <th>category_label</th>\n",
              "      <th>category_label_one_hot</th>\n",
              "      <th>date</th>\n",
              "      <th>headline</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>string_inputs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43742</th>\n",
              "      <td>Sue-Lin Wong, Reuters</td>\n",
              "      <td>ENVIRONMENT</td>\n",
              "      <td>8</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2016-11-01</td>\n",
              "      <td>In Rare Move, China Criticizes Trump Plan To E...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/china-don...</td>\n",
              "      <td>“I believe a wise political leader should take...</td>\n",
              "      <td>In Rare Move, China Criticizes Trump Plan To E...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37929</th>\n",
              "      <td>Julia Brucculieri</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>7</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2017-01-06</td>\n",
              "      <td>Ed Sheeran Just Blessed Us With Not One But Tw...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/ed-sheera...</td>\n",
              "      <td>Get ready to sing.</td>\n",
              "      <td>Ed Sheeran Just Blessed Us With Not One But Tw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138521</th>\n",
              "      <td>Brandon Turner, Contributor\\nVP of Content at ...</td>\n",
              "      <td>BUSINESS</td>\n",
              "      <td>2</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2013-11-23</td>\n",
              "      <td>The Top 10 Mistakes 20-Somethings Make Regardi...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/the-top-1...</td>\n",
              "      <td>At this point in life, many 20-somethings are ...</td>\n",
              "      <td>The Top 10 Mistakes 20-Somethings Make Regardi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170217</th>\n",
              "      <td></td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>3</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2012-12-23</td>\n",
              "      <td>Rejected Folgers Christmas Commercial Goes Hor...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/rejected-...</td>\n",
              "      <td>Wait, what's going on here? Unless they're not...</td>\n",
              "      <td>Rejected Folgers Christmas Commercial Goes Hor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161491</th>\n",
              "      <td>Oyster.com, Contributor\\nThe Hotel Tell-All</td>\n",
              "      <td>TRAVEL</td>\n",
              "      <td>27</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>2013-03-26</td>\n",
              "      <td>The Top 10 Easter Brunches In The U.S.</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/the-top-1...</td>\n",
              "      <td>On the menus: vanilla-dipped brioche French to...</td>\n",
              "      <td>The Top 10 Easter Brunches In The U.S.On the m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  authors  ...                                      string_inputs\n",
              "43742                               Sue-Lin Wong, Reuters  ...  In Rare Move, China Criticizes Trump Plan To E...\n",
              "37929                                   Julia Brucculieri  ...  Ed Sheeran Just Blessed Us With Not One But Tw...\n",
              "138521  Brandon Turner, Contributor\\nVP of Content at ...  ...  The Top 10 Mistakes 20-Somethings Make Regardi...\n",
              "170217                                                     ...  Rejected Folgers Christmas Commercial Goes Hor...\n",
              "161491        Oyster.com, Contributor\\nThe Hotel Tell-All  ...  The Top 10 Easter Brunches In The U.S.On the m...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIgk2u3T2h3n"
      },
      "source": [
        "## Data preprocessing and model declaration\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4annpdP9AQU"
      },
      "source": [
        "We will now tokenize our dataset. Transformers Auto API allows us to retrieve the adequate tokenizer from the given name of a pre-trained model, we have tested this notebook on both uncased base bert and distilgpt2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KM3kD_RnrzP",
        "outputId": "84e0643b-fe77-4671-a057-60d7a4137108"
      },
      "source": [
        "model_name = \"bert-base-uncased\"                                  # use for BERT\n",
        "cls_token  = 0                                                    # use for BERT\n",
        "\n",
        "# model_name = 'distilgpt2'                                         # use for gpt-2\n",
        "# cls_token = -1                                                    # use for gpt-2\n",
        "\n",
        "d_input = 2**7                                                    # chosen dimensionality for the input\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# tokenizer.pad_token = tokenizer.eos_token                         # use for gpt-2. Define pad token as eos token for gpt-2 tokenizer\n",
        "\n",
        "input_features = np.array(tokenizer.batch_encode_plus(              # tokenize our inputs\n",
        "                    df['string_inputs'].astype('str'), \n",
        "                    pad_to_max_length=True,\n",
        "                    truncation = True,\n",
        "                    max_length=d_input)['input_ids'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4MuYO6P9DaD"
      },
      "source": [
        "Lets define some training parameters. We will use the tf.data API with [autotuned prefetching](https://www.tensorflow.org/api_docs/python/tf/data/experimental#AUTOTUNE) and the Keras pipeline for optimal training speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkp8AEJhoALH"
      },
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32*strategy.num_replicas_in_sync\n",
        "AUTO = tf.data.experimental.AUTOTUNE                           # as suggested in kaggle.com/philculliton/a-simple-tf-2-1-notebook"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXn2rVja-rLM"
      },
      "source": [
        "Now we split our training examples into a training and a test sets, we will not use a validation set as for time constraints we dont have the intention of performing hyperparameter tuning. We will .repeat() our training tf.data.Dataset for prefetching.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b9WAFRH-qaa"
      },
      "source": [
        "test_fraction = 0.25\n",
        "training_examples, test_examples ,training_labels, test_labels = train_test_split(input_features, one_hot_labels, test_size = test_fraction)\n",
        "training_set = tf.data.Dataset.from_tensor_slices((training_examples, training_labels)).repeat().batch(BATCH_SIZE).prefetch(AUTO)\n",
        "test_set = tf.data.Dataset.from_tensor_slices((test_examples, test_labels)).batch(BATCH_SIZE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py_W8RjwARYw"
      },
      "source": [
        "Lets now declare and compile our model on TPU. Transformers Auto API provides a tf.keras.Layer encapsulating the entire transformer, we can now freely use this layer via Keras sequential or functional API. \n",
        "\n",
        "We will stack a softmax dense layer with dropout regularization on top of the transformer for multi-class clasification. cls_token indicates the position of the classification token for a given architecture, \n",
        "- for BERT this token is at the position 0 of the latent representation. \n",
        "\n",
        "- GPT-2 was not trained with an explicit clasification token, but we can choose the last position as this one inherits context from the entire sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO7k7k8Q6Urt"
      },
      "source": [
        "def declare_transformer(transformer_layer, d_input, cls_token, n_classes, dropout_frac = 0.25):\n",
        "    \n",
        "    input = tf.keras.layers.Input(shape=(d_input,), dtype=tf.int32)\n",
        "    transformer_output = transformer_layer(input)[0]\n",
        "    cls_output = transformer_output[:, cls_token, :]\n",
        "    dropout_output = tf.keras.layers.Dropout(dropout_frac)(cls_output)\n",
        "    output = tf.keras.layers.Dense(n_classes, activation='softmax')(dropout_output)\n",
        "    model = tf.keras.Model(inputs=input, outputs=output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U60KvyaX6a8p",
        "outputId": "ddfd88fa-5d6c-4e90-ed93-f74e2c3b9d15"
      },
      "source": [
        "loss = 'categorical_crossentropy'\n",
        "\n",
        "with strategy.scope():\n",
        "    transformer_layer = TFAutoModel.from_pretrained(model_name)\n",
        "    model = declare_transformer(transformer_layer = transformer_layer, \n",
        "                                d_input = d_input, \n",
        "                                cls_token = cls_token, \n",
        "                                n_classes = len(categories),\n",
        "                                dropout_frac = 0.25)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=3e-5), loss=loss, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128)]             0         \n",
            "_________________________________________________________________\n",
            "tf_bert_model (TFBertModel)  ((None, 128, 768), (None, 109482240 \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice (T [(None, 768)]             0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 33)                25377     \n",
            "=================================================================\n",
            "Total params: 109,507,617\n",
            "Trainable params: 109,507,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9a8eEx4KGK6"
      },
      "source": [
        "## Training and testing\n",
        "\n",
        "Now we can train our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0TqZMio6jgI",
        "outputId": "148246e0-f195-4c67-9bd2-c31c21a4984a"
      },
      "source": [
        "n_steps = len(training_labels) // BATCH_SIZE\n",
        "\n",
        "train_log = model.fit(\n",
        "                training_set,\n",
        "                steps_per_epoch=n_steps,\n",
        "                epochs=10,\n",
        "                verbose = 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  2/588 [..............................] - ETA: 3:21:29 - loss: 3.7345 - accuracy: 0.0508WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.2271s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.2271s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "588/588 [==============================] - 178s 303ms/step - loss: 1.3345 - accuracy: 0.6304\n",
            "Epoch 2/10\n",
            "588/588 [==============================] - 137s 233ms/step - loss: 0.8863 - accuracy: 0.7361\n",
            "Epoch 3/10\n",
            "588/588 [==============================] - 137s 234ms/step - loss: 0.7140 - accuracy: 0.7840\n",
            "Epoch 4/10\n",
            "588/588 [==============================] - 137s 234ms/step - loss: 0.5611 - accuracy: 0.8274\n",
            "Epoch 5/10\n",
            "588/588 [==============================] - 138s 234ms/step - loss: 0.4270 - accuracy: 0.8670\n",
            "Epoch 6/10\n",
            "588/588 [==============================] - 137s 234ms/step - loss: 0.3198 - accuracy: 0.8983\n",
            "Epoch 7/10\n",
            "588/588 [==============================] - 137s 234ms/step - loss: 0.2353 - accuracy: 0.9239\n",
            "Epoch 8/10\n",
            "588/588 [==============================] - 138s 234ms/step - loss: 0.1793 - accuracy: 0.9415\n",
            "Epoch 9/10\n",
            "588/588 [==============================] - 138s 234ms/step - loss: 0.1363 - accuracy: 0.9554\n",
            "Epoch 10/10\n",
            "588/588 [==============================] - 138s 234ms/step - loss: 0.1038 - accuracy: 0.9658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPZ8GqrpKqAs"
      },
      "source": [
        "And measure its performance on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JF438D9GQ0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42a34fa-fb58-4523-a0d7-d7048976fec5"
      },
      "source": [
        "predictions = model.predict(test_set, verbose = 0)\n",
        "one_hot_preds = np.argmax(predictions, axis = 1)\n",
        "true_classes = np.argmax(test_labels, axis = 1)\n",
        "pred_category = [categories[x] for x in one_hot_preds]\n",
        "true_category = [categories[x] for x in true_classes]\n",
        "accuracy = sklearn.metrics.accuracy_score(pred_category, true_category)\n",
        "print(\"test set accuracy is {} for {}\".format(accuracy, model_name))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set accuracy is 0.7226271557732903 for bert-base-uncased\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1tKuvk7LuNO"
      },
      "source": [
        "After 10 training epochs, a test set performance of around 72% was observed for BERT and around 70% for GPT-2 for the cleaned dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTjiaMTz9LaK"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}